{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: Policy Search\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The player **taking the last object wins**.\n",
    "\n",
    "* Task3.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task3.2: An agent using evolved rules\n",
    "* Task3.3: An agent using minmax\n",
    "* Task3.4: An agent using reinforcement learning\n",
    "\n",
    "## Deadlines ([AoE](https://en.wikipedia.org/wiki/Anywhere_on_Earth))\n",
    "\n",
    "* Sunday, December 4th for Task3.1 and Task3.2\n",
    "* Sunday, December 11th for Task3.3 and Task3.4\n",
    "* Sunday, December 18th for all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from typing import Callable\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "from operator import xor\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s %(levelname)s: %(message)s\", level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "        self.player = 0\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply     \n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n",
    "        self.player = 1 - self.player\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(bytes([*sorted(self.rows), self.player]))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return all(map(lambda x: x[0] == x[1], zip(sorted(self.rows), sorted(other.rows)))) and self.player == other.player\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My fixed-rule agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genome = namedtuple(\"Genome\", \"aggressivity, longest_first, how_many\")\n",
    "Individual = namedtuple(\"Individual\", \"genome, fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_strategy(genome: Genome) -> Callable:\n",
    "    def evolvable(state: Nim) -> Nimply:\n",
    "        # data = cook_status(state)\n",
    "        aggressive: bool = random.random() < genome.aggressivity\n",
    "        longest_first: bool = random.random() < genome.longest_first\n",
    "        how_many_coeff: float = genome.how_many\n",
    "\n",
    "        # Sort the rows based on the number of elements, the sort is descending or ascending based on if longest_first or not\n",
    "        row_indexes = sorted((i for i in range(len(state.rows)) if state.rows[i] > 0), key=lambda elem: state.rows[elem], reverse=longest_first)\n",
    "\n",
    "        # Select randomly one of the first 50% rows\n",
    "        selected_row_index = random.choice(row_indexes[:int(0.5*len(row_indexes))+1])\n",
    "\n",
    "        # Decide to take at least 1 or half of the objects\n",
    "        take_at_least = 0 if not aggressive else state.rows[selected_row_index]//2\n",
    "        \n",
    "        # Decide to take or not a part of the remaining objects\n",
    "        take_n = max(1, min(take_at_least + int(state.rows[selected_row_index]//2*how_many_coeff), state.rows[selected_row_index]))\n",
    "        ply = Nimply(selected_row_index, take_n)\n",
    "\n",
    "        return ply\n",
    "\n",
    "    return evolvable\n",
    "\n",
    "# Task 3.1 agent\n",
    "not_evovled = make_strategy(Genome(0.5, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other fixed-rule agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n",
    "\n",
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    result = reduce(xor, state.rows)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cook_status(state: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k\n",
    "    ]\n",
    "    # cooked[\"active_rows_number\"] = sum(o > 0 for o in state.rows)\n",
    "    # cooked[\"shortest_row\"] = min((x for x in enumerate(state.rows) if x[1] > 0), key=lambda y: y[1])[0]\n",
    "    # cooked[\"longest_row\"] = max((x for x in enumerate(state.rows)), key=lambda y: y[1])[0]\n",
    "    cooked[\"nim_sum\"] = nim_sum(state)\n",
    "\n",
    "    brute_force = list()\n",
    "    for m in cooked[\"possible_moves\"]:\n",
    "        tmp = deepcopy(state)\n",
    "        tmp.nimming(m)\n",
    "        brute_force.append((m, nim_sum(tmp)))\n",
    "    cooked[\"brute_force\"] = brute_force\n",
    "\n",
    "    return cooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_strategy(state: Nim) -> Nimply:\n",
    "    data = cook_status(state)\n",
    "    return next((bf for bf in data[\"brute_force\"] if bf[1] == 0), data[\"brute_force\"][0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent base policy it's the same of task 3.1, but now I evolve its parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIM_SIZE = 10\n",
    "\n",
    "\n",
    "def evaluate(strategy: Callable, opponent: Callable=optimal_strategy, NUM_MATCHES=100) -> float:\n",
    "    strategies = (strategy, opponent)\n",
    "    won = 0\n",
    "\n",
    "    for m in range(NUM_MATCHES):\n",
    "        nim = Nim(NIM_SIZE)\n",
    "        player = 0\n",
    "        while nim:\n",
    "            ply = strategies[player](nim)\n",
    "            nim.nimming(ply)\n",
    "            player = 1 - player\n",
    "        if player == 1:\n",
    "            won += 1\n",
    "    return won / NUM_MATCHES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolve genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament(population, k=10):\n",
    "    return max(random.choices(population, k=k), key=lambda x: x.fitness)\n",
    "\n",
    "def make_offspring(p1: Individual, p2: Individual, current_best_strategy):\n",
    "    new_genome = []\n",
    "    for i in range(len(p1.genome)):\n",
    "        gene = p1.genome[i] if random.random() > 0.5 else p2.genome[i] # inherit from p1 or p2 based on randomness\n",
    "        gene += random.gauss(0, 0.25) # tweak\n",
    "        gene = max(0, min(gene, 1)) # clip to avoid unammissible solutions\n",
    "        new_genome.append(gene)\n",
    "\n",
    "    new_genome = Genome(*new_genome)\n",
    "    individual = Individual(new_genome, evaluate(make_strategy(new_genome), current_best_strategy)) # create individual and compute fitness\n",
    "    \n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 20\n",
    "POPULATION_SIZE = 40\n",
    "OFFSPRING_SIZE = 200\n",
    "genomes = [Genome(0.5 + random.random()/10, 0.5 + random.random()/10, 0.5 + random.random()/10) for _ in range(POPULATION_SIZE)]\n",
    "\n",
    "# the initial population fitness is computed against gabriele\n",
    "population = list(map(lambda genome: Individual(genome, evaluate(make_strategy(genome), gabriele)), genomes))\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    logging.debug(f\"Starting iteration {i}. Current fitness: {population[0].fitness}\")\n",
    "    logging.debug(f\"Current best:\\nAggressivity\\tLongest first\\tHow many\\n\\\n",
    "{population[0].genome.aggressivity:.2f}\\t\\t{population[0].genome.longest_first:.2f}\\t\\t{population[0].genome.how_many:.2f}\")\n",
    "\n",
    "    offspring = []\n",
    "    for _ in range(OFFSPRING_SIZE):\n",
    "        p1, p2 = tournament(population, k=1), tournament(population, k=1)\n",
    "        o = make_offspring(p1, p2, make_strategy(population[0].genome))\n",
    "        offspring.append(o)\n",
    "    population.extend(offspring)\n",
    "    population = sorted(population, key=lambda individual: individual.fitness, reverse=True)[:POPULATION_SIZE]\n",
    "\n",
    "evolved_individual = population[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2 final match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = (make_strategy(evolved_individual.genome), optimal_strategy)\n",
    "\n",
    "nim = Nim(11)\n",
    "logging.debug(f\"status: Initial board  -> {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategies[player](nim)\n",
    "    nim.nimming(ply)\n",
    "    logging.debug(f\"status: After player {player} -> {nim}\")\n",
    "    player = 1 - player\n",
    "winner = 1 - player\n",
    "logging.info(f\"status: Player {winner} won!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "\n",
    "def possible_actions(state):\n",
    "    possible_moves = [\n",
    "        (r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1) if state.k is None or o <= state.k\n",
    "    ]\n",
    "    return possible_moves\n",
    "\n",
    "\n",
    "def result(state: Nim, action: Nimply):\n",
    "    new_state = deepcopy(state)\n",
    "    new_state.nimming(action)\n",
    "    return new_state\n",
    "\n",
    "def minmax_strategy(state: Nim):\n",
    "    def minmax(state: Nim):\n",
    "        if not state:\n",
    "            return None, 1 if state.player == 1 else -1\n",
    "        opt_func = [max, min]\n",
    "        evaluations = list()\n",
    "        for ply in possible_actions(state):\n",
    "            new_state = result(state, ply)\n",
    "            _, val = minmax(new_state)\n",
    "            evaluations.append((ply, val))\n",
    "        return opt_func[state.player](evaluations, key=lambda k:k[1])\n",
    "    return minmax(state)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 12:27:47,048 DEBUG: status: Initial board  -> <1 3 5>\n",
      "2022-12-13 12:27:47,545 DEBUG: status: After player 0 -> <1 3 2>\n",
      "2022-12-13 12:27:47,545 DEBUG: status: After player 1 -> <0 3 2>\n",
      "2022-12-13 12:27:47,553 DEBUG: status: After player 0 -> <0 2 2>\n",
      "2022-12-13 12:27:47,553 DEBUG: status: After player 1 -> <0 1 2>\n",
      "2022-12-13 12:27:47,553 DEBUG: status: After player 0 -> <0 1 1>\n",
      "2022-12-13 12:27:47,553 DEBUG: status: After player 1 -> <0 0 1>\n",
      "2022-12-13 12:27:47,561 DEBUG: status: After player 0 -> <0 0 0>\n",
      "2022-12-13 12:27:47,561 INFO: status: Player 0 won!\n"
     ]
    }
   ],
   "source": [
    "strategies = (minmax_strategy, optimal_strategy)\n",
    "\n",
    "\n",
    "nim = Nim(3)\n",
    "logging.debug(f\"status: Initial board  -> {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategies[player](nim)\n",
    "    nim.nimming(ply)\n",
    "    logging.debug(f\"status: After player {player} -> {nim}\")\n",
    "    player = 1 - player\n",
    "winner = 1 - player\n",
    "logging.info(f\"status: Player {winner} won!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
